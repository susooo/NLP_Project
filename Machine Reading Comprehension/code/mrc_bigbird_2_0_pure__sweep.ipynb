{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/objectin/Goorm-AI-Team-Project/blob/main/mrc_bigbird.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWFRRN91nPI7",
        "outputId": "65c7d12b-00f0-47e2-b6b6-8e1005cb3e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3311b1b469fc374387b560f66eca503d7b4f73799fbab9899ca06bb446e0c582\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 397, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 529, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 202, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 204, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1493, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1619, in print\n",
            "    extend(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 187, in <genexpr>\n",
            "    result_segments = (\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1254, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/text.py\", line 629, in __rich_console__\n",
            "    lines = self.wrap(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/text.py\", line 1152, in wrap\n",
            "    for line in self.split(allow_blank=True):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/text.py\", line 1003, in split\n",
            "    return Lines([self.copy()])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/text.py\", line 425, in copy\n",
            "    copy_self = Text(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/text.py\", line 132, in __init__\n",
            "    def __init__(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets tokenizers wandb evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "4jhbAP33WUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "ZoQdW4KfWW6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AF_XGiNnmU0k"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "from transformers import pipeline\n",
        "import json\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyCHkpL2mW6z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    COLAB = True\n",
        "except:\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNCpfGQR2oBl"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login('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') # 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knS1wpdMyKqy"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터\n",
        "import random\n",
        "\n",
        "SEED = 42 # 건드리지 말 것\n",
        "\n",
        "TRAIN_SEED = 1 # 이것이 시드\n",
        "\n",
        "MODEL_NAME = \"monologg/kobigbird-bert-base\" #\"klue/roberta-base\" #\"monologg/koelectra-base-v3-discriminator\"\n",
        "batch_name = f'kobigbird-pure{TRAIN_SEED}-{random.randrange(99999999)}' # 여기에 저장할 이름을 적어주세요\n",
        "BATCH_SIZE = 32 # 32 # 128\n",
        "\n",
        "print(batch_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRiI8vuTmYEW"
      },
      "outputs": [],
      "source": [
        "!unzip -o \"/content/drive/MyDrive/Colab Notebooks/custom_dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryNOv4J1gVwj"
      },
      "outputs": [],
      "source": [
        "dataset_plus = load_dataset('ko_nia_normal_squad_all', split='train')\n",
        "dataset_plus_fix = dataset_plus.filter(\n",
        "    lambda example: example['question'].endswith(('는?', '가?', '은?', '나?', '요?'))\n",
        ")\n",
        "\n",
        "squad_plus = dataset_plus_fix.train_test_split(0.91, seed=SEED)\n",
        "# filter: ('래?', '야?', '어?', '나?', '러?', '해?', '대?', '지')\n",
        "\n",
        "squad_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpS2HAplmU0l"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('custom_squad_v2', split='train')\n",
        "squad = dataset.train_test_split(0.1, seed=SEED)\n",
        "\n",
        "squad_augmented = datasets.concatenate_datasets([squad['train'], squad_plus['train']])\n",
        "# squad['validation'] = squad['test']\n",
        "# del squad['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4d26-xAIY8t"
      },
      "outputs": [],
      "source": [
        "# squad['train']['question'][:] # 는? 가? 은? 나? 요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQI1ZBjC8jqL"
      },
      "outputs": [],
      "source": [
        "squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfSG3AptgVwj"
      },
      "outputs": [],
      "source": [
        "squad_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbutSCz-mU0m"
      },
      "outputs": [],
      "source": [
        "print(\"Context: \", squad[\"train\"][0][\"context\"])\n",
        "print(\"Question: \", squad[\"train\"][0][\"question\"])\n",
        "print(\"Answer: \", squad[\"train\"][0][\"answers\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eALa5hCmU0m"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esWyDP0kmU0m"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=1024, # electra: 386, bigbird: 1024\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmG2Lm6BmU0n"
      },
      "outputs": [],
      "source": [
        "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAhuIiBqgVwl"
      },
      "outputs": [],
      "source": [
        "tokenized_squad_augmented = squad_augmented.map(preprocess_function, batched=True, remove_columns=squad_augmented.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_umXuB9emU0n"
      },
      "outputs": [],
      "source": [
        "data_collator = DefaultDataCollator()\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, 'random', 'bayes'\n",
        "    'metric': {\n",
        "      'name': 'loss',\n",
        "      'goal': 'minimize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'learning_rate': {'max': 6e-3, 'min': 1e-6},  # {'max': 6e-4, 'min': 1e-4},\n",
        "        'weight_decay':  {'values': [0.01, 0.03, 0.1, 0.3, 0.5]},\n",
        "        'SchedulerType':{'values': [\"linear\", \"cosine\", \"constant\"]}\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "d9_CxYZUXC2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity =  \"solowosophia13\" # \"goorm-3\"\n",
        "sweep_id = wandb.sweep(sweep_config, entity= entity, project=\"mrc_Bigbird_Hyper_Random\")"
      ],
      "metadata": {
        "id": "YeQDH-ENXE3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_epochs = 3\n",
        "BATCH_SIZE = BATCH_SIZE\n",
        "Learning_rate = 5e-4 # huggingface trainer aurgument default value\n",
        "SchedulerType = \"linear\"\n",
        "\n",
        "config_defaults = {\n",
        "    'epochs': num_train_epochs,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'learning_rate': Learning_rate,\n",
        "    'weight_decay ' : 0.0, # huggingface trainer aurgument default value\n",
        "    'optimizer' :'AdamW',\n",
        "    'SchedulerType': SchedulerType\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "bic99grrXRr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwtUYkx_gVwm"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  with wandb.init(config=config_defaults):\n",
        "    config = wandb.config\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=batch_name,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=config.learning_rate,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        weight_decay=config.weight_decay,\n",
        "        push_to_hub=False,\n",
        "        gradient_accumulation_steps = 8,\n",
        "        lr_scheduler_type=config.SchedulerType,\n",
        "        seed=TRAIN_SEED,\n",
        "        data_seed=SEED,\n",
        "        fp16=True, # 고속화 loose한 정확도\n",
        "        gradient_checkpointing=True, # 메모리 절약 대신 느려짐\n",
        "        report_to=\"wandb\"\n",
        "      )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_squad['train'].select(range(3248)),\n",
        "        eval_dataset=tokenized_squad[\"test\"].select(range(360)),\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    trainer.train() # 3cd543fb602ea1edf2c4a2dc5e6bc604665a1629"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=20)"
      ],
      "metadata": {
        "id": "yl6zcVo1YRfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9RIA00Duyl5"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(batch_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Okt9po9hXr"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\\\n",
        "BMW 코리아(대표 한상윤)는 창립 25주년을 기념하는 ‘BMW 코리아 25주년 에디션’을 한정 출시한다고 밝혔다. 이번 BMW 코리아 25주년 에디션(이하 25주년 에디션)은 BMW 3시리즈와 5시리즈, 7시리즈, 8시리즈 총 4종, 6개 모델로 출시되며, BMW 클래식 모델들로 선보인 바 있는 헤리티지 컬러가 차체에 적용돼 레트로한 느낌과 신구의 조화가 어우러진 차별화된 매력을 자랑한다. 먼저 뉴 320i 및 뉴 320d 25주년 에디션은 트림에 따라 옥스포드 그린(50대 한정) 또는 마카오 블루(50대 한정) 컬러가 적용된다. 럭셔리 라인에 적용되는 옥스포드 그린은 지난 1999년 3세대 3시리즈를 통해 처음 선보인 색상으로 짙은 녹색과 풍부한 펄이 오묘한 조화를 이루는 것이 특징이다. M 스포츠 패키지 트림에 적용되는 마카오 블루는 1988년 2세대 3시리즈를 통해 처음 선보인 바 있으며, 보랏빛 감도는 컬러감이 매력이다. 뉴 520d 25주년 에디션(25대 한정)은 프로즌 브릴리언트 화이트 컬러로 출시된다. BMW가 2011년에 처음 선보인 프로즌 브릴리언트 화이트는 한층 더 환하고 깊은 색감을 자랑하며, 특히 표면을 무광으로 마감해 특별함을 더했다. 뉴 530i 25주년 에디션(25대 한정)은 뉴 3시리즈 25주년 에디션에도 적용된 마카오 블루 컬러가 조합된다. 뉴 740Li 25주년 에디션(7대 한정)에는 말라카이트 그린 다크 색상이 적용된다. 잔잔하면서도 오묘한 깊은 녹색을 발산하는 말라카이트 그린 다크는 장식재로 활용되는 광물 말라카이트에서 유래됐다. 뉴 840i xDrive 그란쿠페 25주년 에디션(8대 한정)은 인도양의 맑고 투명한 에메랄드 빛을 연상케 하는 몰디브 블루 컬러로 출시된다. 특히 몰디브 블루는 지난 1993년 1세대 8시리즈에 처음으로 적용되었던 만큼 이를 오마주하는 의미를 담고 있다.\n",
        "\"\"\"\n",
        "question = \"말라카이트에서 나온 색깔을 사용한 에디션은?\"\n",
        "question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)\n",
        "question_answerer(question=question, context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez3G7wA_B57x"
      },
      "outputs": [],
      "source": [
        "test_path = './custom_squad_v2/test.json'\n",
        "\n",
        "test = []\n",
        "with open(test_path, encoding=\"utf-8\") as f:\n",
        "    squad_ = json.load(f)\n",
        "    for example in squad_[\"data\"]:\n",
        "        title = example.get(\"title\", \"\")\n",
        "        for paragraph in example[\"paragraphs\"]:\n",
        "            context = paragraph[\"context\"]  # do not strip leading blank spaces GH-2585\n",
        "            for qa in paragraph[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                id_ = qa[\"guid\"]\n",
        "\n",
        "                # Features currently used are \"context\", \"question\", and \"answers\".\n",
        "                # Others are extracted here for the ease of future expansions.\n",
        "                test.append({\n",
        "                    \"title\": title,\n",
        "                    \"context\": context,\n",
        "                    \"question\": question,\n",
        "                    \"id\": id_,\n",
        "                })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rMEGOT9NNfl"
      },
      "outputs": [],
      "source": [
        "def levenshtein(s1, s2, debug=False):\n",
        "    if len(s1) < len(s2):\n",
        "        return levenshtein(s2, s1, debug)\n",
        "\n",
        "    if len(s2) == 0:\n",
        "        return len(s1)\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "\n",
        "        if debug:\n",
        "            print(current_row[1:])\n",
        "\n",
        "        previous_row = current_row\n",
        "\n",
        "    return previous_row[-1]\n",
        "\n",
        "def get_levenshtein(eval_preds_, answers):\n",
        "    distances = []\n",
        "    for i in range(len(eval_preds_)):\n",
        "        mini = 999999999999\n",
        "        for ans in answers[i]['text']:\n",
        "            lev = levenshtein(eval_preds_[i]['answer'], ans)\n",
        "            \n",
        "            if mini > lev:\n",
        "                mini = lev\n",
        "                \n",
        "        distances.append(mini)\n",
        "\n",
        "    mean_distance = sum(distances) / len(distances)\n",
        "    \n",
        "    return mean_distance\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xs2Lb_BeXOT"
      },
      "outputs": [],
      "source": [
        "def screen_pred(pred):\n",
        "    length = len(pred['answer'])\n",
        "    cond = (length > 40 and pred['score'] < 1) or (pred['score'] < 0.5 and length > 20) or pred['score'] < 0.1\n",
        "    return cond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3ZtiEZZD5et"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for data in tqdm(test):\n",
        "    preds.append(question_answerer(question=data['question'], context=data['context']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7vxMuOH_hVD"
      },
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnPRmyxc3LSR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('blank.csv')\n",
        "blanked = 0\n",
        "for i in range(len(preds)):\n",
        "    pred = preds[i]\n",
        "    if screen_pred(pred):\n",
        "        df['Predicted'][i] = ''\n",
        "        blanked += 1\n",
        "    else:\n",
        "        df['Predicted'][i] = pred['answer']\n",
        "\n",
        "print(f'Blanked preds: {blanked}, total preds: {len(preds)}')\n",
        "\n",
        "df = df.set_index('Id')\n",
        "\n",
        "df.to_csv('pred.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvGvhRa_dC_d"
      },
      "outputs": [],
      "source": [
        "train_preds = []\n",
        "\n",
        "for data in tqdm(squad['train']):\n",
        "    train_preds.append(question_answerer(question=data['question'], context=data['context']))\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(train_preds)):\n",
        "    pred = train_preds[i]\n",
        "    length = len(pred['answer'])\n",
        "    if screen_pred(pred):\n",
        "        train_preds[i]['answer'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYou7RYHo7s0"
      },
      "outputs": [],
      "source": [
        "train_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODgUsM-ldCqp"
      },
      "outputs": [],
      "source": [
        "lev_score = get_levenshtein(train_preds, squad['train']['answers'])\n",
        "print(f'Train Lev Score: {lev_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv6R1BJdFmRx"
      },
      "outputs": [],
      "source": [
        "eval = []\n",
        "eval_preds = []\n",
        "\n",
        "for data in tqdm(squad['test']):\n",
        "    eval_preds.append(question_answerer(question=data['question'], context=data['context']))\n",
        "\n",
        "for i in range(len(eval_preds)):\n",
        "    pred = eval_preds[i]\n",
        "    if screen_pred(pred):\n",
        "        eval_preds[i]['answer'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaMZbltJ_kOK"
      },
      "outputs": [],
      "source": [
        "lev_score_test = get_levenshtein(eval_preds, squad['test']['answers'])\n",
        "\n",
        "print(f'Eval Lev Score: {lev_score_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLilGiWeF3Rw"
      },
      "outputs": [],
      "source": [
        "# eval = []\n",
        "# eval_preds = []\n",
        "\n",
        "# limit = 10000\n",
        "\n",
        "# for i in trange(limit):\n",
        "#     data = squad_plus['test'][i]\n",
        "\n",
        "#     eval_preds.append(question_answerer(question=data['question'], context=data['context']))\n",
        "# for i in range(len(eval_preds)):\n",
        "#     pred = eval_preds[i]\n",
        "#     length = len(pred['answer'])\n",
        "#     if screen_pred(pred):\n",
        "#         eval_preds[i]['answer'] = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZWqEYIqvtOz"
      },
      "outputs": [],
      "source": [
        "# lev_score_hub = get_levenshtein(eval_preds, squad_plus['test']['answers'])\n",
        "\n",
        "# print(f'AIHUB Eval Lev Score: {lev_score_hub}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPlh4TRo38i8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b7eb502b8bbbe7a9a0e525e1a7d0d7614316929686f914beb4e586429dc455c9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}